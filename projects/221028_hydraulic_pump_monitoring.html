<div class="meta">
    <ul>
        <li>all</li>
        <li>programming</li>
        <li>data science</li>
    </ul>
</div>
<div class="post">
    <div class="post_header" id="post_number_three">
        Hydraulic Pump Monitoring
    </div>
    <div class="post_subtitle">
        Using Sensor Data to Infer Pump Maintenance Scheduling
    </div>
    <div class="post_info">
        Posted on Oct. 28, 2022
    </div>
    <div class="post_body">
        <div class="beginning">
            <img src="projects/hydraulic_pump_monitoring/images/hydraulic_pump_monitoring.png"></img>
        </div>
        <div class="hidden">
            <h4>Data Understanding</h4>

            <p>This data comes from a set of sensor measurements taken during 2205 sixty second cycles of a
            hydraulic pump testing rig. During the testing the pump's maintenance status was recorded. These
            various metrics of the test rigs physical condition will be the target variable for our tests. The
            sensor data will be the predictors.</p>

            <p>The goal will be to use sensor data (such as temperature, tank pressure, vibration magnitude, 
            etc.) to predict the state of the hydraulic pump.</p>

            <p>The data is split between sensors. Each sensor has a specific sample rate qhich cooresponds to the 
            columns in its table. So TS1.txt contains temprature readings from one sensor. Its sample rate was 
            1hz for each 60 second pump cycle. Therefore, in the TS1.txt file there are 60 columns and 2205 
            rows of data.</p>

            <p>Each row represents one full cycle and each column represents one sample (in this case 1 second) 
            of readings from the temperatue sensor. To create features from this data we will need to come up 
            with methods for aggregating each row of the sensor data into a single column of data.</p>

            <h4>Modeling</h4>

            <p>As previously mentioned, the data set includes five target variables – cooler 
            condition, valve condition, internal pump leakage, hydraulic accumulator (hydraulic 
            pressure), and stable flag (stable condition). We determined that each of these target 
            variables were vital to the stakeholder and will likely impact our final recommendation. 
            As a result, several models were created. About two models were created for each target 
            variable. Depending on the variable, utilized, certain features were utilized including 
            simple averages of the 60-second cycle, the average change over the course of the cycle, 
            the average and change every 20-seconds of the cycle, and standard deviation of both the 
            full 60-second cycle and every 20-seconds. To begin, we will utilize a simple logistic 
            regression model. Given the data and the stakeholder’s business problem, it will make most 
            sense to run a grid search on several different model types to determine which produces 
            the highest accuracy.</p>

            <h4>First Model:</h4>

            <h5>Feature, Target Variable: Simple Average, Valve Condition</h5>

            <p>For our first model, we are utilizing the grid search to evaluate the Valve Condition 
            as our target variable and utilizing the average metrics of each cycle (simple average) as 
            our feature. To begin, we will evaluate five different models – a logistic regression 
            model, a decision tree model, a random forest model, a K-nearest neighbors (KNN) model, a 
            support vector machine model, and an XGBoost model. We will run a grid search for each of 
            these models to evaluate the hyperparameters that will produce the highest accuracy 
            scores. As a reminder, Valve Condition, measured as a percentage, includes four 
            classifications – 100 meaning the pump was functioning at optimal switching behavior, 90 
            meaning there was a small lag, 80 meaning there was a severe lag, and 73 meaning the pump 
            was close to total failure.</p>

            <img src="projects/hydraulic_pump_monitoring/images/hyd_001.png"></img>

            <h4>Evaluation</h4>

            <p>After running all of the above models and inspecting their output we determined that 
            XGBoost was the best model to iterate one more time. We were also able to determine which 
            feature/target pairings resulted in the best predictions.</p>

            <p>Below we set up test to see which of the sensors had the best feature importance on 
            average. A series of functions in helpers.py were chained along with some search and 
            result parsing to allow us to extract the relevant statistics.</p>

            <h4>Top 8 Sensors</h4>

            <p>Below are the 8 top performing sensors in predicting the state of the hydraulic pump 
            test rig.</p>

            <img src="projects/hydraulic_pump_monitoring/images/hyd_002.png"></img>

            <h4>Final Results</h4>

            <p>Below we have the metrics from our final models.</p>

            <img src="projects/hydraulic_pump_monitoring/images/hyd_003.png"></img>

            <h5>XGBoost</h5>

            <p>We decided to go with the XGBoost model for our final iteration and Average of cycle 
            thirds as the feature set for each target variable except Cooler Condition. For Cooler 
            Condition we decided to use the Standard Deviation for Cycle 3rds as the feature. This was 
            due to its consistently high score along all our metric axes.</p>

            <h4>Conclusion:</h4>

            <h5>Recommendation:</h5>

            <p>Considering all of the above analysis we would recommend the stakeholder utilize an 
            XGBoost predictive model. According to the numerous models and iterations we ran, the 
            best, most accurate model the stakeholder should utilize is an XGBoost model. Further, to 
            effectively utilize this model, we would recommend utilizing the model to predict a pump’s 
            cooler condition and internal pump leakage. Based on our analysis, these predictive models 
            generated the highest accuracy scores (99%+). While the accuracy score of these models are 
            high, there are reasons the model may not fully solve the business problem. The data we 
            utilized was ultimately collected from a single test rig, meaning the environment in which 
            this test rig was producing the data analyzed was carefully selected by the test 
            coordinators. Therefore, there could have been situations that caused leaks or other 
            faults with the pumps that were not accounted for, such as human error or other extreme 
            situations.</p>

            <h5>Next Steps: </h5>

            <p>Further criteria and analyses could yield additional insights to further inform the 
            stakeholder by:</p>

            <p>Reviewing other testing data. The stakeholder should consider utilizing a data set in 
            addition to the one that was analyzed. As previously mentioned, although the data set 
            included 2200+ records of testing data, this data was collected from a single test rig. 
            Utilizing data from another test rig could be helpful with re-checking the accuracy of our 
            final model and noting if our findings were consistent.</p>

            <p>Collecting real-word data. Another factor the stakeholder should consider is collecting 
            real-world data. It is known that the stakeholder uses specific water pumps with their 
            irrigation systems. As such, the stakeholder should consider setting up a system to 
            collect daily data similar to that of the data set utilized. By doing so, the stakeholder 
            could utilize the final model with the data processed through their irrigation system.</p>
        </div>
        <div class="show_more"><button class="button">Show More</button></div>
    </div> 
</div>
